{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from os.path import exists\n",
    "\n",
    "\n",
    "class SampleDataSet:\n",
    "    \n",
    "    '''\n",
    "    To Take a sample from DataSet\n",
    "    '''\n",
    "    def _get_sample(self, df, n, random_State):\n",
    "        sample_size =n \n",
    "        if sample_size > len(df):\n",
    "            sample_size =len(df)\n",
    "        return df.sample(sample_size,random_state=random_State, replace=False)\n",
    "\n",
    "\n",
    "    def _get_sample_Above_Q(self, df, n, random_State, Q):\n",
    "        sample_size =n \n",
    "        df = df[df[\"length\"] >= df[\"length\"].quantile(Q)]\n",
    "\n",
    "        if sample_size > len(df):\n",
    "            sample_size =len(df)\n",
    "        return df.sample(sample_size,random_state=random_State, replace=False)\n",
    "\n",
    "\n",
    "    def SampleDataBase(self, CSVPath, TotalNumber, MaxLength, MinLength=0, FileORTime=\"File\", Random_State=42):\n",
    "        \"\"\"Taking a sample from the dataset according to length \n",
    "            V 1.0.0\n",
    "        Paramters:\n",
    "                CSVPath str : Location to DataFrame\n",
    "\n",
    "                TotalNumber int : the total number of required samples(Files,Minuts), this number must be divisible by 7 as each class will be the same size\n",
    "\n",
    "                MaxLength double : Max length for each file in seconds\n",
    "\n",
    "                MinLength double : Min length for each file in seconds\n",
    "\n",
    "                FileORTime str :  Sample by file or time as TotalNumber will represent number of files or number of seconds\n",
    "                                File for files OR seconds for time\n",
    "\n",
    "        Return:\n",
    "            DataFrame With sampled files.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # Handeling the input Errors\n",
    "        if TotalNumber % 7 !=0: raise Exception('TotalNumber Must be divisable by 7')\n",
    "        if exists(CSVPath)==False : raise Exception(\"can't find the csv file in this path\")\n",
    "\n",
    "        #Each Class Count\n",
    "        CountClass= TotalNumber//7\n",
    "        \n",
    "        #Read the DataFrame\n",
    "        LanguageDf = pd.read_csv(CSVPath, low_memory=False) \n",
    "        LanguageDf.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "        # LanguageDf=LanguageDf.loc[(LanguageDf[\"length\"] >= MinLength) & (LanguageDf[\"length\"] <= MaxLength )]\n",
    "\n",
    "        #Shafful Dataset\n",
    "        LanguageDf= LanguageDf.sample(frac=1,random_state=Random_State).reset_index(drop=True)\n",
    "\n",
    "        #Check Length OR #Files\n",
    "        if FileORTime == \"File\":\n",
    "            LangFilesCount = LanguageDf.groupby(\"language\")[\"language\"].agg(\"count\")\n",
    "            OutOfRange = LangFilesCount[LangFilesCount < CountClass ]\n",
    "            if len(OutOfRange!=0):\n",
    "                    raise Exception(f\"Can't Sample {CountClass} files from each class as the number is larger than existance files {OutOfRange}\")\n",
    "                \n",
    "        elif FileORTime==\"seconds\":\n",
    "            LangFilesCount = LanguageDf.groupby(\"language\")[\"length\"].agg(\"sum\")\n",
    "            OutOfRange = LangFilesCount[LangFilesCount < CountClass ]\n",
    "            if len(OutOfRange!=0):\n",
    "                    raise Exception(f\"Can't Sample {CountClass} seconds from each class as the number is larger than existance files {OutOfRange}\")\n",
    "\n",
    "\n",
    "        #Final DataFrame\n",
    "        Sampeld_DF =pd.DataFrame(columns= [\"filename\",\"speaker\",\"language\",\"length\",\"gender\",\"accent\",\"datasetname\"])\n",
    "\n",
    "\n",
    "        #Sample based on number of files\n",
    "        if FileORTime == \"File\":\n",
    "            # loop over languages\n",
    "            for language in LanguageDf[\"language\"].unique():\n",
    "\n",
    "                _CountClass=CountClass\n",
    "                print(language)\n",
    "\n",
    "                lang =LanguageDf.loc[LanguageDf[\"language\"]==language]\n",
    "                num_Speakers=len(lang[\"speaker\"].unique())\n",
    "\n",
    "                #Number of samples for every itteration\n",
    "                n_files=5 \n",
    "                while n_files * num_Speakers > _CountClass:\n",
    "                    n_files=n_files-1\n",
    "\n",
    "                if n_files <=0:\n",
    "                      Sampeld_DF= pd.concat([Sampeld_DF,lang.sample(_CountClass, random_state=Random_State, replace=False)], ignore_index=True) \n",
    "\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    #itterate untill get number less than or equel 0 \n",
    "                    while _CountClass - len(lang.groupby('speaker', group_keys=False).apply(lambda x: _get_sample(x, n_files, Random_State))) >=0:\n",
    "                        \n",
    "                        #Take n Samples from each speaker\n",
    "                        sample = lang.groupby('speaker', group_keys=False).apply(lambda x: _get_sample(x, n_files, Random_State))\n",
    "\n",
    "                        #Remove sampled rows from the DataFrame to not select it again\n",
    "                        lang=lang[~lang.filename.isin(sample[\"filename\"]) ]\n",
    "\n",
    "                        #shafful dataset\n",
    "                        lang= lang.sample(frac=1,random_state=Random_State).reset_index(drop=True)\n",
    "\n",
    "                        #Append sampled dataframe to final dataframe                    \n",
    "                        Sampeld_DF= pd.concat([Sampeld_DF,sample], ignore_index=True)\n",
    "\n",
    "                        #reduce the number of remaining rows\n",
    "                        _CountClass = _CountClass - len(sample)\n",
    "                        \n",
    "                        #Change the number of speakers as we droped sampled rows from initial dataset\n",
    "                        num_Speakers=len(lang[\"speaker\"].unique())\n",
    "\n",
    "                        #calculate n_files again as \n",
    "                        while n_files * num_Speakers > _CountClass:\n",
    "                            n_files=n_files-1\n",
    "\n",
    "                        if n_files <=0:\n",
    "                            Sampeld_DF= pd.concat([Sampeld_DF,lang.sample(_CountClass, random_state=Random_State, replace=False)], ignore_index=True)\n",
    "                            break\n",
    "\n",
    "                        if len(sample)==0:\n",
    "                            break\n",
    "\n",
    "            return Sampeld_DF\n",
    "\n",
    "\n",
    "        #Sample based on sum of lengths\n",
    "        elif FileORTime==\"seconds\":\n",
    "            # loop over languages\n",
    "            for language in LanguageDf[\"language\"].unique():\n",
    "                \n",
    "                #Time For each class\n",
    "                Time=CountClass\n",
    "\n",
    "                print(language)\n",
    "\n",
    "                lang =LanguageDf.loc[LanguageDf[\"language\"]==language]\n",
    "\n",
    "                num_Speakers=len(lang[\"speaker\"].unique())\n",
    "\n",
    "                #Number of samples for every itteration\n",
    "                n_files=5 \n",
    "                while n_files * num_Speakers * MaxLength > Time:\n",
    "                    n_files=n_files-1\n",
    "                            \n",
    "                # if number of speakers is more than required sample rows\n",
    "                if n_files <=0:\n",
    "                    \n",
    "                    while Time - Sampeld_DF.loc[Sampeld_DF[\"language\"]==language,\"length\"].sum() > 0 :\n",
    "\n",
    "                        # if len(lang[lang[\"length\"]==max_length]) == 0:\n",
    "                        #     max_length=lang[\"length\"].max()\n",
    "\n",
    "                        #Random sampleing from top 0.05 lengthes\n",
    "                        sample  = lang[(lang[\"length\"] >= lang[\"length\"].quantile(0.95)) & (~lang[\"speaker\"].isin(Sampeld_DF)) ].sample(1)\n",
    "\n",
    "                        #Remove sampled rows from lang dataframe\n",
    "                        lang=lang[~lang.filename.isin(sample[\"filename\"]) ]\n",
    "                        \n",
    "                        #Shuffel dataset\n",
    "                        lang= lang.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "                        #Append to final dataframe\n",
    "                        Sampeld_DF= pd.concat([Sampeld_DF,sample], ignore_index=True)\n",
    "\n",
    "                            \n",
    "                else:\n",
    "                \n",
    "                    while  Time -Sampeld_DF.loc[Sampeld_DF[\"language\"]==language,\"length\"].sum()  > 0:\n",
    "                        \n",
    "                        #Take n Samples from top 0.02 lengths from each speaker\n",
    "                        sample = lang.groupby('speaker', group_keys=False).apply(lambda x: _get_sample_Above_Q(x,n_files,32,0.98))\n",
    "\n",
    "                        #Remove sampled rows from dataframe\n",
    "                        lang=lang[~lang.filename.isin(sample[\"filename\"]) ]\n",
    "\n",
    "                        #Shuffel dataFrame\n",
    "                        lang= lang.sample(frac=1, random_state=32).reset_index(drop=True)\n",
    "\n",
    "                        #append to final dataframe\n",
    "                        Sampeld_DF= pd.concat([Sampeld_DF,sample], ignore_index=True)\n",
    "\n",
    "                        #Update number of speakers as we removed sampled rows\n",
    "                        num_Speakers=len(lang[\"speaker\"].unique())\n",
    "\n",
    "                        # reselected the best n_files based on new num_Speakers\n",
    "                        while n_files * num_Speakers * MaxLength > Time - Sampeld_DF.loc[Sampeld_DF[\"language\"]==language,\"length\"].sum() :\n",
    "                            n_files=n_files-1\n",
    "\n",
    "                        #if remains files number in lower than the #Speakers\n",
    "                        if n_files <=0:\n",
    "                            while Time - Sampeld_DF.loc[Sampeld_DF[\"language\"]==language,\"length\"].sum() > 0 :\n",
    "\n",
    "                                # if len(lang[lang[\"length\"]==max_length]) == 0:\n",
    "                                #     max_length=lang[\"length\"].max()\n",
    "\n",
    "                                sample  = lang[ lang[\"length\"] >= lang[\"length\"].quantile(0.98)].sample(1)\n",
    "\n",
    "                                lang=lang[~lang.filename.isin(sample[\"filename\"]) ]\n",
    "\n",
    "                                lang= lang.sample(frac=1, random_state=32).reset_index(drop=True)\n",
    "\n",
    "                                Sampeld_DF= pd.concat([Sampeld_DF,sample], ignore_index=True)    \n",
    "                            break\n",
    "\n",
    "            return Sampeld_DF      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Enter number of files greater then files in languages</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "ar\n",
      "en\n",
      "pt\n",
      "fr\n",
      "es\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "C = SampleDataBase(\"../../DataSets/FinalDataSet/FinalDataSet.csv\", 1000 *7, 8, 0, FileORTime=\"File\") \n",
    "#PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.to_csv(\"Data1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Enter wrong path</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "can't find the csv file in this path",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\GP\\Code\\SampleDataSet\\SampleDataBase.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m C \u001b[39m=\u001b[39m SampleDataBase(\u001b[39m\"\u001b[39;49m\u001b[39m../../DataSets/FinalDataSetd/FinalDataSet.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m10000\u001b[39;49m \u001b[39m*\u001b[39;49m\u001b[39m7\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m0\u001b[39;49m, FileORTime\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mFile\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32md:\\GP\\Code\\SampleDataSet\\SampleDataBase.ipynb Cell 8\u001b[0m in \u001b[0;36mSampleDataBase\u001b[1;34m(CSVPath, TotalNumber, MaxLength, MinLength, FileORTime, Random_State)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y104sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Handeling the input Errors\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y104sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mif\u001b[39;00m TotalNumber \u001b[39m%\u001b[39m \u001b[39m7\u001b[39m \u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m: \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mTotalNumber Must be divisable by 7\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y104sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mif\u001b[39;00m exists(CSVPath)\u001b[39m==\u001b[39m\u001b[39mFalse\u001b[39;00m : \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find the csv file in this path\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y104sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m#Each Class Count\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y104sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m CountClass\u001b[39m=\u001b[39m TotalNumber\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m7\u001b[39m\n",
      "\u001b[1;31mException\u001b[0m: can't find the csv file in this path"
     ]
    }
   ],
   "source": [
    "C = SampleDataBase(\"../../DataSets/FinalDataSetd/FinalDataSet.csv\", 10000 *7, 8, 0, FileORTime=\"File\")  \n",
    "#PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Enter length greater then lanugages length</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Can't Sample 6000000000 seconds from each class as the number is larger than existance files language\nar    192580.226041\nde    104031.616063\nen    383535.235000\nes     81203.794688\nfr    119100.033500\nit     55683.777313\npt    141412.916816\nName: length, dtype: float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\GP\\Code\\SampleDataSet\\SampleDataBase.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m C \u001b[39m=\u001b[39m SampleDataBase(\u001b[39m\"\u001b[39;49m\u001b[39m../../DataSets/FinalDataSet/FinalDataSet.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m100000000\u001b[39;49m \u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m \u001b[39m*\u001b[39;49m\u001b[39m7\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m0\u001b[39;49m, FileORTime\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseconds\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32md:\\GP\\Code\\SampleDataSet\\SampleDataBase.ipynb Cell 10\u001b[0m in \u001b[0;36mSampleDataBase\u001b[1;34m(CSVPath, TotalNumber, MaxLength, MinLength, FileORTime, Random_State)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y110sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m    OutOfRange \u001b[39m=\u001b[39m LangFilesCount[LangFilesCount \u001b[39m<\u001b[39m CountClass ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y110sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m    \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(OutOfRange\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y110sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt Sample \u001b[39m\u001b[39m{\u001b[39;00mCountClass\u001b[39m}\u001b[39;00m\u001b[39m seconds from each class as the number is larger than existance files \u001b[39m\u001b[39m{\u001b[39;00mOutOfRange\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y110sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m#Final DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/Code/SampleDataSet/SampleDataBase.ipynb#Y110sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m Sampeld_DF \u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mspeaker\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39maccent\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdatasetname\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mException\u001b[0m: Can't Sample 6000000000 seconds from each class as the number is larger than existance files language\nar    192580.226041\nde    104031.616063\nen    383535.235000\nes     81203.794688\nfr    119100.033500\nit     55683.777313\npt    141412.916816\nName: length, dtype: float64"
     ]
    }
   ],
   "source": [
    "C = SampleDataBase(\"../../DataSets/FinalDataSet/FinalDataSet.csv\", 100000000 *60 *7, 8, 0, FileORTime=\"seconds\")  \n",
    "#PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling based on files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbce3ab015948f9d7a38d0a4c6629e1339f6d90306f3d65fd7273a0ce3b29204"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
