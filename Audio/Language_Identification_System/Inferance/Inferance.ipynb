{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from PIL import Image\n",
    "plt.figure(figsize=(20, 20))\n",
    "import pandas as pd\n",
    "import io\n",
    "import torch\n",
    "from VGGModel import VGGModel\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inferance:\n",
    "    def __init__(self,Model_path):\n",
    "        \"\"\" Make prediction for given Audio File \"\"\"\n",
    "        self.model = VGGModel().Build_Model()\n",
    "        self.model.load_state_dict(torch.load(Model_path, map_location=torch.device('cpu')))\n",
    "        self.model.eval() \n",
    "        self.langs= ['ar', 'de', 'en', 'es', 'fr', 'it', 'pt']\n",
    "\n",
    "\n",
    "    def _Generate_MelSpec(self, audio_path):\n",
    "        \"\"\"Generate Mel_spectogram image from Audio file\"\"\"\n",
    "        y, sr = librosa.load(audio_path ,duration = 8, sr=16000)\n",
    "        y = librosa.util.fix_length(y, size=8*16000)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=sr, fmin=20)\n",
    "        \n",
    "        img = librosa.display.specshow(librosa.power_to_db(S, ref=np.max),\n",
    "                                    x_axis='time', y_axis='mel', fmax=sr )\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='jpg')\n",
    "        buf.seek(0)\n",
    "        image = Image.open(buf).resize((224, 224))\n",
    "\n",
    "        # img_array = np.array(image)\n",
    "\n",
    "        buf.close()\n",
    "        plt.close()\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def Predict(self, Image_Path):\n",
    "        PIL_img = self._Generate_MelSpec(Image_Path)\n",
    "        pil_to_tensor = transforms.ToTensor()(PIL_img).unsqueeze_(0)\n",
    "        prediction = self.model(pil_to_tensor)\n",
    "        _,Pred =torch.max(prediction, dim=1)\n",
    "        # prediction = self.model(pil_to_tensor)\n",
    "        return self.langs[Pred.numpy()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer = Inferance(\"VGG_Mel128_200_M_12088_27801.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "de\n",
      "en\n",
      "es\n",
      "en\n",
      "es\n",
      "es\n"
     ]
    }
   ],
   "source": [
    "print(infer.Predict(\"../../../../../DataSets/FinalDataSet/clips/ar-f-0-10-CV.wav\"))\n",
    "print(infer.Predict(\"../../../../../DataSets/FinalDataSet/clips/de-n-6-6-VF.wav\"))\n",
    "print(infer.Predict(\"../../../../../DataSets/FinalDataSet/clips/en-n-33-4-VF.wav\"))\n",
    "print(infer.Predict(\"../../../../../DataSets/FinalDataSet/clips/es-n-5-0-VF.wav\"))\n",
    "print(infer.Predict(\"../../../../../DataSets/FinalDataSet/clips/fr-n-1731-0-VF.wav\"))\n",
    "print(infer.Predict(\"../../../../../DataSets/FinalDataSet/clips/it-n-2-3-VF.wav\"))\n",
    "print(infer.Predict(\"../../../../../DataSets/FinalDataSet/clips/pt-m-158-10145-CV.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbce3ab015948f9d7a38d0a4c6629e1339f6d90306f3d65fd7273a0ce3b29204"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
