{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import Important  Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import self as self\n",
    "import sns as sns\n",
    "import  tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import voting as voting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ID   Latitude  Longitude  Day  Hour  Minute  Duration  RemainingTime  \\\n0   1  45.442142 -75.303369    1     4      13        40             40   \n1   1  45.442154 -75.304366    1     4      23        40             30   \n2   1  45.442104 -75.303963    1     4      33        40             20   \n3   1  45.441868 -75.303577    1     4      43        40             10   \n4   2  45.447727 -75.147722    2    15      49        30             30   \n\n   Resources  Coverage  OnPeakHours  GridNumber  Ligitimacy  \n0          9        91            0      131380           1  \n1          9        91            0      131380           1  \n2          9        91            0      121996           1  \n3          9        91            0      121996           1  \n4          5        47            0      140784           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n      <th>Ligitimacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>45.442142</td>\n      <td>-75.303369</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>40</td>\n      <td>40</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>131380</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>45.442154</td>\n      <td>-75.304366</td>\n      <td>1</td>\n      <td>4</td>\n      <td>23</td>\n      <td>40</td>\n      <td>30</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>131380</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>45.442104</td>\n      <td>-75.303963</td>\n      <td>1</td>\n      <td>4</td>\n      <td>33</td>\n      <td>40</td>\n      <td>20</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>121996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>45.441868</td>\n      <td>-75.303577</td>\n      <td>1</td>\n      <td>4</td>\n      <td>43</td>\n      <td>40</td>\n      <td>10</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>121996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>45.447727</td>\n      <td>-75.147722</td>\n      <td>2</td>\n      <td>15</td>\n      <td>49</td>\n      <td>30</td>\n      <td>30</td>\n      <td>5</td>\n      <td>47</td>\n      <td>0</td>\n      <td>140784</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (r'D:\\uottawa\\smart cities\\final project\\MCSDatasetNEXTCONLab.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:12]\n",
    "y = df.iloc[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Implement  classic classifier Adaboot and RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def models(model, x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    model = model.fit(x_train, y_train)\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    report_test = classification_report(y_test, y_test_pred)\n",
    "    return (model, y_train_pred, y_test_pred, accuracy_train, accuracy_test, report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RF, AB = RandomForestClassifier(), AdaBoostClassifier()\n",
    "#Rf\n",
    "model_RF, y_train_pred_RF, y_test_pred_RF, accuracy_train_RF, accuracy_test_RF, report_RF = models(RF, x, y)\n",
    "#AB\n",
    "model_AB, y_train_pred_AB, y_test_pred_AB, accuracy_train_AB, accuracy_test_AB, report_AB = models(AB, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       354\n",
      "           1       1.00      1.00      1.00      2543\n",
      "\n",
      "    accuracy                           1.00      2897\n",
      "   macro avg       1.00      0.98      0.99      2897\n",
      "weighted avg       1.00      1.00      1.00      2897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9958577839143942"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test_RF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       354\n",
      "           1       0.96      0.98      0.97      2543\n",
      "\n",
      "    accuracy                           0.95      2897\n",
      "   macro avg       0.92      0.86      0.89      2897\n",
      "weighted avg       0.95      0.95      0.95      2897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9540904383845358"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test_AB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bar Chart for RF and AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame({'Model':['Random Forest', 'AdaBoost'],\n",
    "'Accuracy on Training Data':[accuracy_train_RF, accuracy_train_AB,\n",
    "                             ],\n",
    "'Accuracy on Testing Data':[accuracy_test_RF, accuracy_test_AB,\n",
    "                            ] ,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 1.0)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for testing data\n",
    "bar_plot_test = sns.barplot(data = df_2, x = 'Model', y = 'Accuracy on Testing Data')\n",
    "bar_plot_test.set_ylim(0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Constants and hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes =2\n",
    "latent_dim = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training Tasks: (11587, 12)\n",
      "Shape of training labels: (11587, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_labels = keras.utils.to_categorical(y_train,2)\n",
    "x_train=x_train.astype(np.float32)\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training Tasks: {x_train.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculating the number of input channel for the generator and discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 14\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = 12 + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 7, 64)             256       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 7, 64)             0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 128)            24704     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 4, 128)            0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,089\n",
      "Trainable params: 25,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(discriminator_in_channels,1)),\n",
    "        layers.Conv1D(64, 3, strides=2, padding=\"same\",),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1D(128, 3, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        layers.Dense(1,activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 256)               33536     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,492\n",
      "Trainable params: 84,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense(256),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(128,),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(12,),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CGAN Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "91/91 [==============================] - 3s 7ms/step - g_loss: 0.6856 - d_loss: 0.7140\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 1.3587 - d_loss: 0.6018\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7307 - d_loss: 0.7155\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.6387 - d_loss: 0.7181\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.6570 - d_loss: 0.7017\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7005 - d_loss: 0.6785\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7003 - d_loss: 0.6905\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7260 - d_loss: 0.6935\n",
      "Epoch 9/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7219 - d_loss: 0.6866\n",
      "Epoch 10/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.6796 - d_loss: 0.6844\n",
      "Epoch 11/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7134 - d_loss: 0.6855\n",
      "Epoch 12/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7139 - d_loss: 0.7057\n",
      "Epoch 13/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.6870 - d_loss: 0.6953\n",
      "Epoch 14/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7040 - d_loss: 0.6679\n",
      "Epoch 15/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7123 - d_loss: 0.7084\n",
      "Epoch 16/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.6663 - d_loss: 0.6967\n",
      "Epoch 17/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7391 - d_loss: 0.6898\n",
      "Epoch 18/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.6981 - d_loss: 0.6944\n",
      "Epoch 19/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.6997 - d_loss: 0.6815\n",
      "Epoch 20/20\n",
      "91/91 [==============================] - 1s 7ms/step - g_loss: 0.7133 - d_loss: 0.6847\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1cb55e0ba90>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator,generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_Tasks, one_hot_labels = data\n",
    "\n",
    "\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_Tasks)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake Tasks.\n",
    "        generated_Tasks = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real TASKS . Note that we are concatenating the labels\n",
    "        # with these tasks here.\n",
    "        fake_tasks_and_labels = tf.concat([generated_Tasks, one_hot_labels],axis=1)\n",
    "        real_task_with_labels=tf.concat([real_Tasks,one_hot_labels],axis=1)\n",
    "\n",
    "        combined_tasks = tf.concat(\n",
    "            [fake_tasks_and_labels, real_task_with_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake tasks.\n",
    "        labels = tf.concat(\n",
    "            [tf.zeros((batch_size, 1)), tf.ones((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_tasks)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_tasks = self.generator(random_vector_labels)\n",
    "            fake_tasks_and_labels = tf.concat([fake_tasks, one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_tasks_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "              ID   Latitude  Longitude       Day       Hour     Minute  \\\n0    2164.191406  45.525280 -75.250420  3.234113  18.733908  50.271618   \n1    2654.715088  45.537876 -75.252861  3.193758  17.586891  52.816406   \n2    2793.319336  45.535858 -75.268608  3.711390  18.019270  55.651287   \n3    2447.290527  45.540722 -75.238930  3.147765  16.152683  48.160370   \n4    2616.924805  45.517120 -75.252983  3.229619  16.571630  48.567574   \n..           ...        ...        ...       ...        ...        ...   \n995  2911.718506  45.538204 -75.299927  3.202884  18.344418  50.038589   \n996  2764.692871  45.559906 -75.267921  3.102384  19.564892  55.206802   \n997  2550.270508  45.557354 -75.249130  3.172266  18.796974  52.730751   \n998  2510.116699  45.521545 -75.302826  3.221419  16.367828  50.451279   \n999  2575.687988  45.577679 -75.281128  3.347672  19.825811  56.224461   \n\n      Duration  RemainingTime  Resources   Coverage  OnPeakHours  \\\n0    33.131824      37.222622   9.351373  65.270920     0.065401   \n1    31.906689      37.692921   9.807094  55.841099     0.035596   \n2    35.540157      42.264355   9.724212  67.410965     0.011787   \n3    38.465481      44.436760   9.722855  63.353432     0.207019   \n4    38.402740      44.091831   9.684939  57.219501     0.086321   \n..         ...            ...        ...        ...          ...   \n995  36.223682      41.391911  11.232533  56.283077    -0.140102   \n996  29.392933      41.252239  10.644953  50.007210    -0.176534   \n997  35.779236      39.912083  11.910395  51.306702     0.006625   \n998  36.394600      48.959949  11.149899  49.521553    -0.040699   \n999  36.419006      41.402393  10.801638  55.103027    -0.129262   \n\n        GridNumber  \n0    196024.218750  \n1    183793.390625  \n2    189091.484375  \n3    203018.296875  \n4    200958.437500  \n..             ...  \n995  220041.046875  \n996  219416.609375  \n997  217897.140625  \n998  188033.609375  \n999  214103.500000  \n\n[1000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2164.191406</td>\n      <td>45.525280</td>\n      <td>-75.250420</td>\n      <td>3.234113</td>\n      <td>18.733908</td>\n      <td>50.271618</td>\n      <td>33.131824</td>\n      <td>37.222622</td>\n      <td>9.351373</td>\n      <td>65.270920</td>\n      <td>0.065401</td>\n      <td>196024.218750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2654.715088</td>\n      <td>45.537876</td>\n      <td>-75.252861</td>\n      <td>3.193758</td>\n      <td>17.586891</td>\n      <td>52.816406</td>\n      <td>31.906689</td>\n      <td>37.692921</td>\n      <td>9.807094</td>\n      <td>55.841099</td>\n      <td>0.035596</td>\n      <td>183793.390625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2793.319336</td>\n      <td>45.535858</td>\n      <td>-75.268608</td>\n      <td>3.711390</td>\n      <td>18.019270</td>\n      <td>55.651287</td>\n      <td>35.540157</td>\n      <td>42.264355</td>\n      <td>9.724212</td>\n      <td>67.410965</td>\n      <td>0.011787</td>\n      <td>189091.484375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2447.290527</td>\n      <td>45.540722</td>\n      <td>-75.238930</td>\n      <td>3.147765</td>\n      <td>16.152683</td>\n      <td>48.160370</td>\n      <td>38.465481</td>\n      <td>44.436760</td>\n      <td>9.722855</td>\n      <td>63.353432</td>\n      <td>0.207019</td>\n      <td>203018.296875</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2616.924805</td>\n      <td>45.517120</td>\n      <td>-75.252983</td>\n      <td>3.229619</td>\n      <td>16.571630</td>\n      <td>48.567574</td>\n      <td>38.402740</td>\n      <td>44.091831</td>\n      <td>9.684939</td>\n      <td>57.219501</td>\n      <td>0.086321</td>\n      <td>200958.437500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>2911.718506</td>\n      <td>45.538204</td>\n      <td>-75.299927</td>\n      <td>3.202884</td>\n      <td>18.344418</td>\n      <td>50.038589</td>\n      <td>36.223682</td>\n      <td>41.391911</td>\n      <td>11.232533</td>\n      <td>56.283077</td>\n      <td>-0.140102</td>\n      <td>220041.046875</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>2764.692871</td>\n      <td>45.559906</td>\n      <td>-75.267921</td>\n      <td>3.102384</td>\n      <td>19.564892</td>\n      <td>55.206802</td>\n      <td>29.392933</td>\n      <td>41.252239</td>\n      <td>10.644953</td>\n      <td>50.007210</td>\n      <td>-0.176534</td>\n      <td>219416.609375</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>2550.270508</td>\n      <td>45.557354</td>\n      <td>-75.249130</td>\n      <td>3.172266</td>\n      <td>18.796974</td>\n      <td>52.730751</td>\n      <td>35.779236</td>\n      <td>39.912083</td>\n      <td>11.910395</td>\n      <td>51.306702</td>\n      <td>0.006625</td>\n      <td>217897.140625</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>2510.116699</td>\n      <td>45.521545</td>\n      <td>-75.302826</td>\n      <td>3.221419</td>\n      <td>16.367828</td>\n      <td>50.451279</td>\n      <td>36.394600</td>\n      <td>48.959949</td>\n      <td>11.149899</td>\n      <td>49.521553</td>\n      <td>-0.040699</td>\n      <td>188033.609375</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>2575.687988</td>\n      <td>45.577679</td>\n      <td>-75.281128</td>\n      <td>3.347672</td>\n      <td>19.825811</td>\n      <td>56.224461</td>\n      <td>36.419006</td>\n      <td>41.402393</td>\n      <td>10.801638</td>\n      <td>55.103027</td>\n      <td>-0.129262</td>\n      <td>214103.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate Tasks that would be generated in\n",
    "# between the interpolation + 2 (start and last TASKS).\n",
    "num_tasks = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "noise = tf.random.normal(shape=(num_tasks, latent_dim))\n",
    "noise_with_label=tf.concat([noise,keras.utils.to_categorical([0]*num_tasks,2)],1)\n",
    "\n",
    "fake_tasks=trained_gen.predict(noise_with_label)\n",
    "fake_tasks=pd.DataFrame(scaler.inverse_transform(fake_tasks),columns=df.columns[0:12])\n",
    "fake_tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 10 using mixed data set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "New dataset with fake tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without Discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.16419141e+03,  4.55252800e+01, -7.52504196e+01, ...,\n         6.52709198e+01,  6.54008389e-02,  1.96024219e+05],\n       [ 2.65471509e+03,  4.55378761e+01, -7.52528610e+01, ...,\n         5.58410988e+01,  3.55958343e-02,  1.83793391e+05],\n       [ 2.79331934e+03,  4.55358582e+01, -7.52686081e+01, ...,\n         6.74109650e+01,  1.17872655e-02,  1.89091484e+05],\n       ...,\n       [-9.77744436e-02,  7.10110181e-01, -5.07246183e-01, ...,\n        -1.71428571e-01, -1.00000000e+00,  7.07218435e-01],\n       [-4.60365091e-01, -9.47784415e-01, -2.26452261e-01, ...,\n        -2.85714286e-02, -1.00000000e+00, -9.51267183e-01],\n       [-5.81395349e-01, -8.04883341e-01, -2.39396997e-01, ...,\n         7.71428571e-01, -1.00000000e+00, -8.04928382e-01]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_x_Test = np.concatenate((fake_tasks,x_test) , axis = 0)\n",
    "New_y_Test =  np.concatenate((y_test.values,np.zeros(num_tasks)), axis = 0).astype(\"int\")\n",
    "New_x_Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def models(model, x, y):\n",
    "    y_test_pred_mix = model.predict(x)\n",
    "    accuracy_test = accuracy_score(y, y_test_pred_mix)\n",
    "    report_test = classification_report(y,y_test_pred_mix)\n",
    "    return y_test_pred_mix, accuracy_test, report_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\nadai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nadai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nadai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nadai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Rf\n",
    "y_test_pred_RF_mix, accuracy_test_RF_mix, report_RF_mix = models(model_RF, New_x_Test, New_y_Test)\n",
    "#AB\n",
    "y_test_pred_AB_mix, accuracy_test_AB_mix, report_AB_mix = models(model_AB,New_x_Test, New_y_Test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1354\n",
      "           1       0.65      1.00      0.79      2543\n",
      "\n",
      "    accuracy                           0.65      3897\n",
      "   macro avg       0.33      0.50      0.39      3897\n",
      "weighted avg       0.43      0.65      0.52      3897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_RF_mix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6525532460867334"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test_RF_mix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.00      0.00      1354\n",
      "           1       0.65      1.00      0.79      2543\n",
      "\n",
      "    accuracy                           0.65      3897\n",
      "   macro avg       0.36      0.50      0.39      3897\n",
      "weighted avg       0.45      0.65      0.51      3897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_AB_mix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6497305619707467"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test_AB_mix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bar Chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({'Model':['Random Forest', 'AdaBoost',],\n",
    "'Accuracy on Testing Data':[accuracy_test_RF_mix, accuracy_test_AB_mix,\n",
    "                           ] ,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 1.0)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for testing data\n",
    "bar_plot_test = sns.barplot(data = df_new, x = 'Model', y = 'Accuracy on Testing Data')\n",
    "bar_plot_test.set_ylim(0,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After we create mixed test data set with fake tasks  fitted it with RandomForest and Adaboost  and give it lower accuracy than the original test data set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With Discriminator/ cascade framework"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "      0\n0     0\n1     0\n2     0\n3     0\n4     0\n...  ..\n3892  1\n3893  1\n3894  1\n3895  1\n3896  1\n\n[3897 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3892</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3893</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3894</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3895</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3896</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3897 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_desc=cond_gan.discriminator\n",
    "new_labels=keras.utils.to_categorical(New_y_Test,2)\n",
    "New_x_Test_with_labels=tf.concat([New_x_Test,new_labels],axis=1)\n",
    "y_pred_new=trained_desc.predict(New_x_Test_with_labels)\n",
    "y_pred_new=np.apply_along_axis(lambda x:1 if x >0.5 else 0 ,axis=1,arr=y_pred_new)\n",
    "y_pred_new_df=pd.DataFrame(y_pred_new)\n",
    "y_pred_new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "      0\n1000  1\n1001  1\n1002  1\n1005  1\n1006  1\n...  ..\n3892  1\n3893  1\n3894  1\n3895  1\n3896  1\n\n[2417 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1005</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3892</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3893</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3894</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3895</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3896</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2417 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real_tasks=y_pred_new_df[y_pred_new_df[0]==1]\n",
    "Real_tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "               0          1          2         3          4          5   \\\n0     2164.191406  45.525280 -75.250420  3.234113  18.733908  50.271618   \n1     2654.715088  45.537876 -75.252861  3.193758  17.586891  52.816406   \n2     2793.319336  45.535858 -75.268608  3.711390  18.019270  55.651287   \n3     2447.290527  45.540722 -75.238930  3.147765  16.152683  48.160370   \n4     2616.924805  45.517120 -75.252983  3.229619  16.571630  48.567574   \n...           ...        ...        ...       ...        ...        ...   \n3892     0.978995   0.443606  -0.620495  0.000000   0.130435   1.000000   \n3893     0.440860  -0.619198   0.462170 -0.333333  -0.739130   0.762712   \n3894    -0.097774   0.710110  -0.507246 -1.000000   0.739130  -0.966102   \n3895    -0.460365  -0.947784  -0.226452  0.000000   1.000000  -1.000000   \n3896    -0.581395  -0.804883  -0.239397  0.333333  -1.000000  -0.593220   \n\n             6          7         8          9         10             11  \n0     33.131824  37.222622  9.351373  65.270920  0.065401  196024.218750  \n1     31.906689  37.692921  9.807094  55.841099  0.035596  183793.390625  \n2     35.540157  42.264355  9.724212  67.410965  0.011787  189091.484375  \n3     38.465481  44.436760  9.722855  63.353432  0.207019  203018.296875  \n4     38.402740  44.091831  9.684939  57.219501  0.086321  200958.437500  \n...         ...        ...       ...        ...       ...            ...  \n3892   1.000000   1.000000  0.777778   0.800000 -1.000000       0.463310  \n3893   0.600000  -0.600000 -0.555556  -0.542857 -1.000000      -0.609753  \n3894   0.200000  -0.600000  0.555556  -0.171429 -1.000000       0.707218  \n3895   0.200000   0.200000  0.777778  -0.028571 -1.000000      -0.951267  \n3896   0.600000  -0.200000  0.555556   0.771429 -1.000000      -0.804928  \n\n[3897 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2164.191406</td>\n      <td>45.525280</td>\n      <td>-75.250420</td>\n      <td>3.234113</td>\n      <td>18.733908</td>\n      <td>50.271618</td>\n      <td>33.131824</td>\n      <td>37.222622</td>\n      <td>9.351373</td>\n      <td>65.270920</td>\n      <td>0.065401</td>\n      <td>196024.218750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2654.715088</td>\n      <td>45.537876</td>\n      <td>-75.252861</td>\n      <td>3.193758</td>\n      <td>17.586891</td>\n      <td>52.816406</td>\n      <td>31.906689</td>\n      <td>37.692921</td>\n      <td>9.807094</td>\n      <td>55.841099</td>\n      <td>0.035596</td>\n      <td>183793.390625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2793.319336</td>\n      <td>45.535858</td>\n      <td>-75.268608</td>\n      <td>3.711390</td>\n      <td>18.019270</td>\n      <td>55.651287</td>\n      <td>35.540157</td>\n      <td>42.264355</td>\n      <td>9.724212</td>\n      <td>67.410965</td>\n      <td>0.011787</td>\n      <td>189091.484375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2447.290527</td>\n      <td>45.540722</td>\n      <td>-75.238930</td>\n      <td>3.147765</td>\n      <td>16.152683</td>\n      <td>48.160370</td>\n      <td>38.465481</td>\n      <td>44.436760</td>\n      <td>9.722855</td>\n      <td>63.353432</td>\n      <td>0.207019</td>\n      <td>203018.296875</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2616.924805</td>\n      <td>45.517120</td>\n      <td>-75.252983</td>\n      <td>3.229619</td>\n      <td>16.571630</td>\n      <td>48.567574</td>\n      <td>38.402740</td>\n      <td>44.091831</td>\n      <td>9.684939</td>\n      <td>57.219501</td>\n      <td>0.086321</td>\n      <td>200958.437500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3892</th>\n      <td>0.978995</td>\n      <td>0.443606</td>\n      <td>-0.620495</td>\n      <td>0.000000</td>\n      <td>0.130435</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.777778</td>\n      <td>0.800000</td>\n      <td>-1.000000</td>\n      <td>0.463310</td>\n    </tr>\n    <tr>\n      <th>3893</th>\n      <td>0.440860</td>\n      <td>-0.619198</td>\n      <td>0.462170</td>\n      <td>-0.333333</td>\n      <td>-0.739130</td>\n      <td>0.762712</td>\n      <td>0.600000</td>\n      <td>-0.600000</td>\n      <td>-0.555556</td>\n      <td>-0.542857</td>\n      <td>-1.000000</td>\n      <td>-0.609753</td>\n    </tr>\n    <tr>\n      <th>3894</th>\n      <td>-0.097774</td>\n      <td>0.710110</td>\n      <td>-0.507246</td>\n      <td>-1.000000</td>\n      <td>0.739130</td>\n      <td>-0.966102</td>\n      <td>0.200000</td>\n      <td>-0.600000</td>\n      <td>0.555556</td>\n      <td>-0.171429</td>\n      <td>-1.000000</td>\n      <td>0.707218</td>\n    </tr>\n    <tr>\n      <th>3895</th>\n      <td>-0.460365</td>\n      <td>-0.947784</td>\n      <td>-0.226452</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.200000</td>\n      <td>0.200000</td>\n      <td>0.777778</td>\n      <td>-0.028571</td>\n      <td>-1.000000</td>\n      <td>-0.951267</td>\n    </tr>\n    <tr>\n      <th>3896</th>\n      <td>-0.581395</td>\n      <td>-0.804883</td>\n      <td>-0.239397</td>\n      <td>0.333333</td>\n      <td>-1.000000</td>\n      <td>-0.593220</td>\n      <td>0.600000</td>\n      <td>-0.200000</td>\n      <td>0.555556</td>\n      <td>0.771429</td>\n      <td>-1.000000</td>\n      <td>-0.804928</td>\n    </tr>\n  </tbody>\n</table>\n<p>3897 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_x_Test_df=pd.DataFrame(New_x_Test)\n",
    "New_x_Test_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2         3         4         5    6    7   \\\n1000  0.993998  0.732562  0.299011  0.666667 -0.913043  0.355932 -0.6 -1.0   \n1001  0.295324  0.602653 -0.480717 -1.000000  0.565217 -0.830508  0.2 -0.6   \n1002 -0.679420  0.497367 -0.598442 -1.000000  0.652174  0.050847  0.6  0.2   \n1005 -0.723431  0.853849 -0.753141  0.000000  0.913043 -0.016949  0.2  0.2   \n1006 -0.272318  0.654998  0.384789 -0.333333  0.043478 -0.186441 -1.0 -1.0   \n...        ...       ...       ...       ...       ...       ...  ...  ...   \n3892  0.978995  0.443606 -0.620495  0.000000  0.130435  1.000000  1.0  1.0   \n3893  0.440860 -0.619198  0.462170 -0.333333 -0.739130  0.762712  0.6 -0.6   \n3894 -0.097774  0.710110 -0.507246 -1.000000  0.739130 -0.966102  0.2 -0.6   \n3895 -0.460365 -0.947784 -0.226452  0.000000  1.000000 -1.000000  0.2  0.2   \n3896 -0.581395 -0.804883 -0.239397  0.333333 -1.000000 -0.593220  0.6 -0.2   \n\n            8         9    10        11  \n1000 -0.777778 -1.000000 -1.0  0.707281  \n1001 -0.333333  0.542857 -1.0  0.609659  \n1002 -0.333333 -0.085714 -1.0  0.512090  \n1005  0.555556 -0.400000 -1.0  0.853536  \n1006  0.111111 -0.742857 -1.0  0.658512  \n...        ...       ...  ...       ...  \n3892  0.777778  0.800000 -1.0  0.463310  \n3893 -0.555556 -0.542857 -1.0 -0.609753  \n3894  0.555556 -0.171429 -1.0  0.707218  \n3895  0.777778 -0.028571 -1.0 -0.951267  \n3896  0.555556  0.771429 -1.0 -0.804928  \n\n[2417 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000</th>\n      <td>0.993998</td>\n      <td>0.732562</td>\n      <td>0.299011</td>\n      <td>0.666667</td>\n      <td>-0.913043</td>\n      <td>0.355932</td>\n      <td>-0.6</td>\n      <td>-1.0</td>\n      <td>-0.777778</td>\n      <td>-1.000000</td>\n      <td>-1.0</td>\n      <td>0.707281</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>0.295324</td>\n      <td>0.602653</td>\n      <td>-0.480717</td>\n      <td>-1.000000</td>\n      <td>0.565217</td>\n      <td>-0.830508</td>\n      <td>0.2</td>\n      <td>-0.6</td>\n      <td>-0.333333</td>\n      <td>0.542857</td>\n      <td>-1.0</td>\n      <td>0.609659</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>-0.679420</td>\n      <td>0.497367</td>\n      <td>-0.598442</td>\n      <td>-1.000000</td>\n      <td>0.652174</td>\n      <td>0.050847</td>\n      <td>0.6</td>\n      <td>0.2</td>\n      <td>-0.333333</td>\n      <td>-0.085714</td>\n      <td>-1.0</td>\n      <td>0.512090</td>\n    </tr>\n    <tr>\n      <th>1005</th>\n      <td>-0.723431</td>\n      <td>0.853849</td>\n      <td>-0.753141</td>\n      <td>0.000000</td>\n      <td>0.913043</td>\n      <td>-0.016949</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>0.555556</td>\n      <td>-0.400000</td>\n      <td>-1.0</td>\n      <td>0.853536</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>-0.272318</td>\n      <td>0.654998</td>\n      <td>0.384789</td>\n      <td>-0.333333</td>\n      <td>0.043478</td>\n      <td>-0.186441</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>0.111111</td>\n      <td>-0.742857</td>\n      <td>-1.0</td>\n      <td>0.658512</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3892</th>\n      <td>0.978995</td>\n      <td>0.443606</td>\n      <td>-0.620495</td>\n      <td>0.000000</td>\n      <td>0.130435</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.777778</td>\n      <td>0.800000</td>\n      <td>-1.0</td>\n      <td>0.463310</td>\n    </tr>\n    <tr>\n      <th>3893</th>\n      <td>0.440860</td>\n      <td>-0.619198</td>\n      <td>0.462170</td>\n      <td>-0.333333</td>\n      <td>-0.739130</td>\n      <td>0.762712</td>\n      <td>0.6</td>\n      <td>-0.6</td>\n      <td>-0.555556</td>\n      <td>-0.542857</td>\n      <td>-1.0</td>\n      <td>-0.609753</td>\n    </tr>\n    <tr>\n      <th>3894</th>\n      <td>-0.097774</td>\n      <td>0.710110</td>\n      <td>-0.507246</td>\n      <td>-1.000000</td>\n      <td>0.739130</td>\n      <td>-0.966102</td>\n      <td>0.2</td>\n      <td>-0.6</td>\n      <td>0.555556</td>\n      <td>-0.171429</td>\n      <td>-1.0</td>\n      <td>0.707218</td>\n    </tr>\n    <tr>\n      <th>3895</th>\n      <td>-0.460365</td>\n      <td>-0.947784</td>\n      <td>-0.226452</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>0.777778</td>\n      <td>-0.028571</td>\n      <td>-1.0</td>\n      <td>-0.951267</td>\n    </tr>\n    <tr>\n      <th>3896</th>\n      <td>-0.581395</td>\n      <td>-0.804883</td>\n      <td>-0.239397</td>\n      <td>0.333333</td>\n      <td>-1.000000</td>\n      <td>-0.593220</td>\n      <td>0.6</td>\n      <td>-0.2</td>\n      <td>0.555556</td>\n      <td>0.771429</td>\n      <td>-1.0</td>\n      <td>-0.804928</td>\n    </tr>\n  </tbody>\n</table>\n<p>2417 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real_Features=New_x_Test_df.iloc[Real_tasks.index,:]\n",
    "Real_Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Cascade_RF=model_RF.score(Real_Features,Real_tasks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Cascade_AB=model_AB.score(Real_Features,Real_tasks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=[\"RF\",\"AB\"],y=[Cascade_RF,Cascade_AB])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Discriminator able to remove fake tasks and this help two classifier model (Rf and AB) to classify correctly with high accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}